

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=dark>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Feng Tao">
  <meta name="keywords" content="">
  
    <meta name="description" content="​	Asyncflow">
<meta property="og:type" content="article">
<meta property="og:title" content="Asyncflow">
<meta property="og:url" content="http://example.com/2023/08/04/%E9%9D%A2%E8%AF%95/Asyncflow/index.html">
<meta property="og:site_name" content="胤凯">
<meta property="og:description" content="​	Asyncflow">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/images/go.png">
<meta property="article:published_time" content="2023-08-04T03:05:31.000Z">
<meta property="article:modified_time" content="2023-08-05T08:23:26.242Z">
<meta property="article:author" content="Feng Tao">
<meta property="article:tag" content="面试">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/images/go.png">
  
  
  
  <title>Asyncflow - 胤凯</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/fluid-extension.css">
<link rel="stylesheet" href="/css/test.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.4","typing":{"enable":true,"typeSpeed":70,"cursorChar":"🎉","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"n0H6ZjcwsAdPc2zfOJM4bxV4-gzGzoHsz","app_key":"rwjeQIHfYJqQvjh2iWuPkYev","server_url":"https://n0h6zjcw.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":true}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>胤凯</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/test/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                <span>友链</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/example/">
                <i class="iconfont icon-brush"></i>
                <span>校园生活</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/none.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Asyncflow"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-08-04 11:05" pubdate>
          2023年8月4日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          15k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          129 分钟
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Asyncflow</h1>
            
            
              <div class="markdown-body">
                
                <p>​	Asyncflow<span id="more"></span></p>
<h1 id="立意"><a href="#立意" class="headerlink" title="立意"></a>立意</h1><h4 id="1、介绍一下你的项目。"><a href="#1、介绍一下你的项目。" class="headerlink" title="1、介绍一下你的项目。"></a>1、介绍一下你的项目。</h4><p><strong>分析：</strong>面试官此时完成不知道任何背景，切勿上来就说有什么模块，而应该从场景上，先说清楚这个项目是什么，解决什么问题，聊清楚之后再介绍一下架构，介绍过程中不需要说太对细节。</p>
<p><strong>回答：</strong></p>
<ul>
<li>从场景上说，Asyncflow 项目是一个 异步任务处理框架，抽象了异步任务中<strong>任务管理</strong>、自动重试、<strong>优先级</strong>等非业务能力，使得异步任务开发成本低并且高效</li>
<li>从架构上来说，Asyncflow 主要分为<strong>服务层 flow server</strong> 和 <strong>执行层 worker</strong>，flow server 是负责提供  <strong>任务创建</strong>、<strong>任务拉取</strong>、<strong>设置任务状态</strong> 等接口。worker 是负责调度的，也可以看作消费者，它会从 flow server 拉取任务，然后执行任务。</li>
</ul>
<h4 id="2、你为什么做这个框架？什么时候使用这个框架？"><a href="#2、你为什么做这个框架？什么时候使用这个框架？" class="headerlink" title="2、你为什么做这个框架？什么时候使用这个框架？"></a>2、你为什么做这个框架？什么时候使用这个框架？</h4><p><strong>分析：</strong> 这个问题很重要，一定要回答好。</p>
<p>​	整体思路是 因为实验室&#x2F;实习&#x2F;工作&#x2F;项目，涉及到这种异步流程，所以想着抽象出来。</p>
<p><strong>回答</strong>：</p>
<p>​	学校实验室招新，新生需要加入飞书，加入飞书之后需要自动给他们创建资源（个人信息等），然后给他们拉入一个统一的群，自动发消息欢迎他们加入实验室，整体上这个流程是有很多步的，中间也有耗时操作，所以适用于异步的流程。</p>
<p>​	同时呢，之前有关注音视频场景，知道腾讯云提供这些音视频能力，比如审核、获取元信息、转码等，一系列流程需要这么一个任务管理框架来调度。</p>
<p>​	于是就想着自己边学边做，实现这么一个框架。</p>
<h4 id="3、Asyncflow-和-消息队列有什么区别？"><a href="#3、Asyncflow-和-消息队列有什么区别？" class="headerlink" title="3、Asyncflow 和 消息队列有什么区别？"></a>3、Asyncflow 和 消息队列有什么区别？</h4><p><strong>分析：</strong>这是很容易问到的问题，因为异步场景最常见的解决方案就是消息队列。</p>
<p>​	这里主要从定位来分析：</p>
<ul>
<li>消息队列定位于消息流转</li>
<li>我们的框架定位于任务管理</li>
</ul>
<p><strong>回答：</strong></p>
<p>​	定位不一样，Asyncflow 是一个框架，消息队列是个组件。消息队列确实在异步场景用的比较多，本质上就是做消息的流转。但是 Asyncflow 还支持阶段性任务，也就是可以更新任务，以及 Asyncflow 还可以做完善的任务管理，这两点是消息队列比较缺失的。</p>
<h4 id="4、为什么不用业界已有的异步任务框架？"><a href="#4、为什么不用业界已有的异步任务框架？" class="headerlink" title="4、为什么不用业界已有的异步任务框架？"></a>4、为什么不用业界已有的异步任务框架？</h4><p><strong>分析：</strong>最难的问题之一，出发点从定位、轻量级来说</p>
<p><strong>回答：</strong></p>
<p>​	业界比较有出名的任务框架，celery 和 machinery ，celery 是 python 编写的，machinery 是 go 模仿 celery 实现的。</p>
<p>​	他们可能都更倾向于消息流转，而不是任务管理。这里我们需要的是一个能快速实现异步任务的轻量级框架，支持上下文更改，这是 celery 和 machinery 的定义不一样的。同时呢，像 machinery 功能很齐全，支持延迟任务机制、任务定义机制、任务回调机制、任务流模式等一系列机制，很多我们并用不上，我们想做的就是一个支持异步任务管理、调度的轻量级框架。</p>
<h4 id="5、这个项目是你一个人做的还是团队做的？你们是怎么协作的？"><a href="#5、这个项目是你一个人做的还是团队做的？你们是怎么协作的？" class="headerlink" title="5、这个项目是你一个人做的还是团队做的？你们是怎么协作的？"></a>5、这个项目是你一个人做的还是团队做的？你们是怎么协作的？</h4><p><strong>分析：</strong>了解你是不是真的做了这个项目，以及你在其中的定位</p>
<p><strong>回答：</strong></p>
<p>​	由我牵头，和学校实验室的两个同学一起进行，我负责方案设计和主要调度逻辑 worker 调度、分表、分布式锁，他们只是负责 flower 对外接口的实现，比如创建任务、处理任务接口的实现，但是像设计这些都是我做的。</p>
<h4 id="6、你的使用场景是什么？"><a href="#6、你的使用场景是什么？" class="headerlink" title="6、你的使用场景是什么？"></a>6、你的使用场景是什么？</h4><p><strong>分析：</strong>框架项目，面试官肯定会好奇，你是基于什么场景来做的，条件有限可以说一个场景。</p>
<p><strong>回答：</strong></p>
<p>​	在学校实验室招新的时候，新生加入飞书，期间有审核、创建资源、建群、发欢迎消息等一系列动作，整个是异步的场景，实现这个能力的时候写了一些任务管理的代码。</p>
<p>​	同时呢，之前有关注音视频场景，知道腾讯云提供这些音视频能力，比如审核、获取元信息、转码等，一系列流程需要这么一个任务管理框架来调度。</p>
<p>​	我就把这些重复代码抽象了出来。</p>
<h1 id="存储、接入、部署"><a href="#存储、接入、部署" class="headerlink" title="存储、接入、部署"></a>存储、接入、部署</h1><h4 id="1、你的框架怎么接入呢？"><a href="#1、你的框架怎么接入呢？" class="headerlink" title="1、你的框架怎么接入呢？"></a>1、你的框架怎么接入呢？</h4><p><strong>分析：</strong>一个业务团队找到你，问你怎么才能使用这个框架，你该怎么给他介绍</p>
<p><strong>回答：</strong></p>
<pre><code class="hljs"> 首先，用户需要自己部署框架依赖的中间件，我们框架依赖 MySQL 和 Redis，用户自己要先部署好，同时我们框架任务依赖 MySQL 中的位置信息表、 任务配置表、任务信息表，这个也得先创建好
</code></pre>
<p>​	接着，就可以部署 flower（启动 flowsvr 程序），我们可以选择使用脚本去访问 flowsvr 对应的创建任务接口，然后 flowsvr 会和我们部署的 MySQL 交互，将任务存储到对应的任务消息表（任务信息表名字和这个任务类型强相关）。</p>
<p>​	接下来，我们需要想办法消费任务。</p>
<ol>
<li>第一步，将任务执行的逻辑，写到 worker 里面，逻辑写进 worker 之后，等拉到对应类型的任务，也就可以执行了，具体一点来说，worker 通过 sdk 的方式提供了三个接口方法，任务需要实现这三个接口方法，将业务逻辑写进三个接口方法，才可以将这类任务注册进框架。</li>
</ol>
<blockquote>
<p>这三个接口方法分别是：</p>
<p>ContextLoad：框架的使用者也就是用户，得定义如何解析上下文（比如如何将上下文字符串解析到程序中使用）</p>
<p>HandleProcess：用户得自己定义一种任务类型的真正处理逻辑</p>
<p>HandleFinish：用于处理任务完成后的逻辑，也就是在任务成功或失败后，需要执行的一些后续操作。例如可以在这个方法中发送任务完成的通知，记录任务的执行日志等等。具体的逻辑根据业务需要而定</p>
</blockquote>
<pre><code class="hljs">2. 第二部，就是部署 worker，消费任务
</code></pre>
<p>​	说是部署，其实就是启动这个 worker 程序，然后 worker 安装用户定义的逻辑去执行</p>
<h4 id="2、你的框架怎么部署呢？"><a href="#2、你的框架怎么部署呢？" class="headerlink" title="2、你的框架怎么部署呢？"></a>2、你的框架怎么部署呢？</h4><p><strong>分析：</strong> 检验你的框架实际有没有使用过</p>
<p><strong>回答：</strong> 我们是提供框架，业务方可以根据自己的需要部署，一般我们推荐 flower 和 worker 都是多机部署，MySQL 或 Reids 使用主从模式即可</p>
<h4 id="3、worker-是托管在框架这边的服务器吗？还是对于异步任务的模块-如果-worker-托管在异步任务处理框架这边的服务器，那处理完之后的数据怎么协会到业务方的数据库？"><a href="#3、worker-是托管在框架这边的服务器吗？还是对于异步任务的模块-如果-worker-托管在异步任务处理框架这边的服务器，那处理完之后的数据怎么协会到业务方的数据库？" class="headerlink" title="3、worker 是托管在框架这边的服务器吗？还是对于异步任务的模块?如果 worker 托管在异步任务处理框架这边的服务器，那处理完之后的数据怎么协会到业务方的数据库？"></a>3、worker 是托管在框架这边的服务器吗？还是对于异步任务的模块?如果 worker 托管在异步任务处理框架这边的服务器，那处理完之后的数据怎么协会到业务方的数据库？</h4><p><strong>分析：</strong> 问这个问题，说明面试官对框架的定位还不是特别理解，需要讲述一下</p>
<p><strong>回答：</strong></p>
<p>​	我们这边是提供框架。如果一个业务团队想接入，需要自己部署 flowsvr、worker。如果业务下有几个子业务，我们是推荐业务提供公用的 flowsvr，子业务都调用这个 flowsvr，worker 的话 可以子业务自己部署。</p>
<h4 id="4、为什么存储用-MySQL-不用-Redis？"><a href="#4、为什么存储用-MySQL-不用-Redis？" class="headerlink" title="4、为什么存储用 MySQL 不用 Redis？"></a>4、为什么存储用 MySQL 不用 Redis？</h4><p><strong>分析：</strong> 用 MySQL 我们是有考虑的，首先 MySQL可以持久化分析，数据更可靠，其次 MySQL 支持管理化场景，比如获取任务表的时候，要根据任务类型和任务状态去获取。</p>
<p>​	虽然 Redis 也能持久化，但是毕竟没有 MySQL 那么可靠，其次呢，Redis 也不支持关系型查询</p>
<blockquote>
<p>Redis和MySQL是两种不同类型的数据库，它们各自有着不同的特点和适用场景。因此，将它们的可靠性进行直接对比是不太合适的，而应该从不同角度来理解它们的可靠性。</p>
<ol>
<li><p>数据持久化：Redis是一个基于内存的缓存数据库，它将数据存储在内存中，可以提供快速的读写访问速度。但由于数据存储在内存中，一旦服务器重启或崩溃，数据将会丢失，这导致了Redis在持久化方面相对不如MySQL。为了解决这个问题，Redis提供了持久化机制，可以将数据定期写入磁盘或者在每次写入数据时进行日志记录，以便在重启后恢复数据。</p>
</li>
<li><p>ACID特性：MySQL是一种关系型数据库，支持ACID（原子性、一致性、隔离性和持久性）特性，这意味着MySQL可以确保数据的完整性和一致性。而Redis虽然提供了持久化机制，但不支持完整的ACID特性，因为它主要用作缓存数据库，对一致性和持久性的要求相对较低。</p>
</li>
<li><p>数据复制和高可用性：MySQL支持主从复制和多主复制，可以实现数据的备份和高可用性。在MySQL主从复制中，一个主数据库将数据复制到多个从数据库，从数据库可以接受读取请求，从而分担主数据库的读负载，并且在主数据库发生故障时可以切换到从数据库继续提供服务。而Redis也支持主从复制，但在复制过程中可能会有数据延迟，因此对于对数据一致性要求非常高的场景，MySQL的可靠性会更好一些。</p>
</li>
</ol>
<p>总体而言，MySQL作为一种成熟的关系型数据库，适用于需要高度可靠性和一致性的应用场景。而Redis则适用于对读写性能要求较高，对数据一致性要求相对较低的缓存和临时存储场景。在实际应用中，可以根据具体的业务需求和数据特点选择合适的数据库解决方案，甚至将Redis和MySQL结合使用，发挥它们各自的优势。</p>
</blockquote>
<p><strong>回答：</strong></p>
<p>​	不用 Redis 的原因是因为 Redis 的可靠性不如 MySQL，以及 Redis 不支持关系型查询，而我们的场景是任务管理场景，涉及的关系型查询还蛮多的，最典型的就是根据状态拉取一批任务来执行。</p>
<h4 id="5、为什么存储用-MySQL-不用-MongoDB？"><a href="#5、为什么存储用-MySQL-不用-MongoDB？" class="headerlink" title="5、为什么存储用 MySQL 不用 MongoDB？"></a>5、为什么存储用 MySQL 不用 MongoDB？</h4><p><strong>分析：</strong> 众多选型中，MongoDB 是最有竞争力的，MongoDB 可以说是最接近关系型的非关系型数据库，性能好、可扩展、支持文档数据库。</p>
<p>​	MongoDB 的局限在于不支持事务和不支持 Join，但我们的场景，其实几乎不用事务和 Join，所以说实话，MongoDB还挺适合我们的场景。</p>
<p>​	我们底层后续也是要支持 Mongo，提供更多能力。</p>
<p>​	回答的时候要偏向实际出发，毕竟很多团队都不用 Mongo，并且也不想引入新的存储组件。</p>
<p><strong>回答：</strong></p>
<p>​	其实 MySQL 和 Mongo 都比较适合我们场景，我们的存储能力查询是封装过的，后面也打算接入 Mongo 作为底层存储之一。现在默认用 MySQL 的原因是因为大多场景，上下文都是简洁的，包括之前调研过飞书机器人、音视频处理等，而且 MySQL 是很多业务团队的基础设施，这样就不用引入新的存储组件，减少运维的容灾成本。</p>
<h4 id="6、上下文怎么存储的，存不下怎么办？"><a href="#6、上下文怎么存储的，存不下怎么办？" class="headerlink" title="6、上下文怎么存储的，存不下怎么办？"></a>6、上下文怎么存储的，存不下怎么办？</h4><p><strong>分析：</strong>先讲常规是不会出现这个问题的，再讲如果出现怎么办？</p>
<p>url 传递：类似于丢到百度云盘上，用的时候再下载回来解析成结构体。</p>
<p><strong>回答：</strong></p>
<p>​	我们是用一个字段 context 存储上下文的，最大 8192 个字节。首先任务大多数情况下，上下文都是简洁的，关键信息才用上下文存储，8192 是够用的。如果遇到真存不下的情况，我们也推荐这里用 url 传递，内容太多走字节的化，走字节还是传递都是不太友好的。</p>
<p>​	（如果感觉面试官不太满意，再说下面）</p>
<p>另外，这里后面也会支持 MongoDB 做底层引擎，上下文过大就可以看作是文档了，这时候用 MongoDB 会比较合适。</p>
<h1 id="任务创建与调度"><a href="#任务创建与调度" class="headerlink" title="任务创建与调度"></a>任务创建与调度</h1><h4 id="1、讲讲任务创建的流程"><a href="#1、讲讲任务创建的流程" class="headerlink" title="1、讲讲任务创建的流程"></a>1、讲讲任务创建的流程</h4><p><strong>分析：</strong> 这个问题没有太大的难度，更多就是看你对流程是否清晰，是否能很好的讲解一个流程</p>
<p><strong>回答：</strong></p>
<p>​	首先，请求通过 http 调用，到达 flowsvr。接着，flowsvr 通过路由找到对应的执行函数，解析参数并检查是否合法。</p>
<p>​	然后开始执行创建任务的逻辑，先查询面前插入的表号，然后讲数据插入数据库，最后构造返回包给调用放。这就是完整的创建任务的流程。</p>
<h4 id="2、讲讲拉取任务接口的流程"><a href="#2、讲讲拉取任务接口的流程" class="headerlink" title="2、讲讲拉取任务接口的流程"></a>2、讲讲拉取任务接口的流程</h4><p><strong>分析：</strong> 考察对任务拉取流程是否掌握，重点在于服务之间的交互流程、服务内的执行逻辑。</p>
<p><strong>回答：</strong></p>
<p>​	worker 发起占据任务请求，flower 接收到之后，会根据路由找到占据任务函数并进行检查参数，接着从数据库拉取一批任务，将这批任务设置为执行中，填充返回包并返回给 worker</p>
<h4 id="3、下面里面对-worker-是手动还是自动发请求拉任务？"><a href="#3、下面里面对-worker-是手动还是自动发请求拉任务？" class="headerlink" title="3、下面里面对 worker 是手动还是自动发请求拉任务？"></a>3、下面里面对 worker 是手动还是自动发请求拉任务？</h4><p><strong>分析：</strong> 这个是主流程的逻辑，这里肯定是自动的。</p>
<p><strong>回答：</strong></p>
<p>​	自动按一定时间间隔去拉取，时间间隔作为任务配置表的参数，用户可以灵活配置。</p>
<h4 id="4、你们的-MySQL-中查询是一大批还是查询一个？"><a href="#4、你们的-MySQL-中查询是一大批还是查询一个？" class="headerlink" title="4、你们的 MySQL 中查询是一大批还是查询一个？"></a>4、你们的 MySQL 中查询是一大批还是查询一个？</h4><p><strong>分析：</strong> 不用顾虑太多，就是问下细节。具体的话，属于占据任务细节，我们是批量拉取，这样效率高一些</p>
<p><strong>回答：</strong> 拉取任务时，我们是一次获取一批任务，这样是为了减少对 MySQL 的请求，节约性能，具体拉多少我们有任务配置表可以配置</p>
<h4 id="5、任务拉取按什么顺序？"><a href="#5、任务拉取按什么顺序？" class="headerlink" title="5、任务拉取按什么顺序？"></a>5、任务拉取按什么顺序？</h4><p><strong>分析：</strong> 这里是问 worker 从 flowsvr 拉取时，以什么顺序拉取任务，比如 10000 个待执行的任务，这次拉取 100 个，是拉到哪 100 个？ 理解清楚之后，其实就是 order_time 的策略了。可以讲讲思考过程，可能会加分</p>
<p><strong>回答：</strong></p>
<p>我们考虑过用创建时间或者更新时间来排序，但都存在弊端：</p>
<ul>
<li>用创建时间排序：如果是多阶段任务，一个阶段任务完成之后，回到队列中，这时候创建时间还是最小的那批，下次调度还是他，这样就无法让出调度给更饥饿的任务。</li>
<li>用更新时间排序，看似没问题，但是我们有个失败重试间隔的配置，即失败之后，多久之后再重试，如果还是按照更新时间，在失败重试间隔到达之前就可能被拉取到了。</li>
</ul>
<p>​	创建时间、更新时间都不行，究其原因，还是排序影响因素很多，不能与单个字段耦合，特别是数据库这两个基本都有的默认字段耦合，所以我们抽象出来一个专门用来排序的字段，用来排序。</p>
<p>​	在任务创建时等于创建时间戳。在任务更新时，等于修改时间戳，但如果是失败之后，还要加上重试间隔。</p>
<p>​	如果有设置优先级，那么优先级也会影响这个排序字段，我需要讲一下吗？（掌握节奏）</p>
<h4 id="6、优先级是怎么做的"><a href="#6、优先级是怎么做的" class="headerlink" title="6、优先级是怎么做的"></a>6、优先级是怎么做的</h4><p><strong>分析：</strong> 这个如果说好了，是个可以加分的点。业界常规用的方案是分为 0~9 这种优先等级，而我们提供了优先多少秒的能力</p>
<p><strong>回答：</strong> </p>
<p>​	优先级通常实现都是几个数字，表示优先级的级别，排序时就先按优先级排序，再按排序字段排序。</p>
<p>​	但这种方案在我们的框架中会引入两个问题：</p>
<ol>
<li>需要将 priority 加入联合索引，影响性能，并且大多时候 priority 都是一样的，这个开销有点亏，而且 priority 不够灵活。</li>
<li>优先级高的任务，即使失败之后，马上又是最先被调度到的，占据资源还容易堵死普通任务。</li>
</ol>
<p>​	所以这里我们采用的方式，是将 priority 秒化，即 priority 不表示级别，而表示优先多少秒，然后将这个数字融入我们的排序字段，这种方案耦合小、成本低、足够灵活适合框架。</p>
<h4 id="7、你说的这个优先级和实现方式，你有没有想过应用场景？如何定义优先级A和优先级B是多少？A比B为什么优先？"><a href="#7、你说的这个优先级和实现方式，你有没有想过应用场景？如何定义优先级A和优先级B是多少？A比B为什么优先？" class="headerlink" title="7、你说的这个优先级和实现方式，你有没有想过应用场景？如何定义优先级A和优先级B是多少？A比B为什么优先？"></a>7、你说的这个优先级和实现方式，你有没有想过应用场景？如何定义优先级A和优先级B是多少？A比B为什么优先？</h4><p><strong>分析：</strong> 挑战你是否有实际场景支持</p>
<p><strong>回答</strong>：</p>
<p>​	我们的优先级，表示优先多少秒。业务可以自行抽象，比如一个视频处理团队，他可以定义超级 VIP，优先级 10 小时，也就是说正常情况下，他都是排到队头，但是如果任务以及阻塞了几天了，他并不是最先执行的，这时候还是优先照顾已经等很久的任务。</p>
<p>​	也可以定义一个 SSVIP，这种 VIP就是优先 1 年，也就是说基本无视时间，即使队列积压了几天的任务，他也直接最先处理。</p>
<h4 id="8、你觉得你的优先级设计是绝对优先还是相对优先？"><a href="#8、你觉得你的优先级设计是绝对优先还是相对优先？" class="headerlink" title="8、你觉得你的优先级设计是绝对优先还是相对优先？"></a>8、你觉得你的优先级设计是绝对优先还是相对优先？</h4><p><strong>分析：</strong> 绝对优先就容易形成阻塞</p>
<p><strong>回答：</strong></p>
<p>​	我们的优先级是逻辑上相对优先级，因为绝对容易形成阻塞。当然功能上我们是可以实现绝对优先级的，比如一个业务，其他任务都是优先个几十秒、几分钟。某些特别重要的任务设置优先级 100 年，这就是绝对优先了。</p>
<h4 id="9、重试间隔是什么机制"><a href="#9、重试间隔是什么机制" class="headerlink" title="9、重试间隔是什么机制"></a>9、重试间隔是什么机制</h4><p><strong>分析：</strong> </p>
<p>​	有时候失败之后不希望立即重试，以免浪费不必要资源	</p>
<p>​	这个问题主要是考察设计细节，通过细节看你能否自圆其说</p>
<p><strong>回答：</strong>	</p>
<p>​	通常而言，普通的重试间隔需求无非是均匀重试和渐进式重试</p>
<p>​	我们的框架默认使用一个 interval 字段支持渐进式重试，interval 表示最大的间隔秒。考虑到确实有部分场景，希望均价重试，但我们这里并不想新增一个标记字段来配合表示，这里选择用了一种很巧妙的方式，即使用负数表示均匀重试时间。</p>
<p>​	其实应该还有更丰富的重试策略，更进一步可能需要列表甚至 lua 这种解析策略，但我们也调研了业界 celery 等竞品，都不会做这么复杂，这里我们提供两种策略已经是很完善了。</p>
<h4 id="10、flower-怎么知道任务超时了，定时器轮询吗？判断任务是否超时，有无更好的办法？"><a href="#10、flower-怎么知道任务超时了，定时器轮询吗？判断任务是否超时，有无更好的办法？" class="headerlink" title="10、flower 怎么知道任务超时了，定时器轮询吗？判断任务是否超时，有无更好的办法？"></a>10、flower 怎么知道任务超时了，定时器轮询吗？判断任务是否超时，有无更好的办法？</h4><p> <strong>分析：</strong> 首先这里需要和面试官对齐所谓的任务超时是什么情况，这里容易有歧义的，我们这里所谓的任务超时，是指一个任务被占据之后，长时间处于执行中。</p>
<p>​	这个长时间的判断标准，是由业务来设置的：</p>
<ul>
<li>如果我们调用腾讯云图片审核能力，也就是发起一个接口调用，那这个阶段的占据时间通常不会超过一分钟，1 分钟就是最大执行时间</li>
<li>如果下载一个文件，那时间可能就是5分钟或者更久</li>
</ul>
<p><strong>回答：</strong> </p>
<p>​	我们使用定时器轮询，这里是抽象了一个任务治理模块，去扫描这些超过最大执行时间的任务，最大执行时间也是业务根据检验设置的，这类任务一般都是由于异常原因，worker 没有上报结果导致，可能是 worker 挂掉等原因，所以需要任务治理去发现。</p>
<p>​	目前架构下没有更好的方式了，这种完全失联只能扫描。</p>
<blockquote>
<p>如果发现了任务超时，设置为待执行，超时就是过长时间在执行中，只能重置。</p>
</blockquote>
<h4 id="11、任务如果执行中失败了怎么办？"><a href="#11、任务如果执行中失败了怎么办？" class="headerlink" title="11、任务如果执行中失败了怎么办？"></a>11、任务如果执行中失败了怎么办？</h4><p><strong>分析：</strong> 考察失败情况处理</p>
<p><strong>回答：</strong> </p>
<p>​	框架支持重做，如果任务执行失败了并且没有超过重试次数，就会将状态改成待执行状态，等待下次被调度执行；如果执行失败并且超过重试次数了，那么就是彻底失败，将状态改成失败。</p>
<h4 id="12、-worker-怎么竞争任务？"><a href="#12、-worker-怎么竞争任务？" class="headerlink" title="12、 worker 怎么竞争任务？"></a>12、 worker 怎么竞争任务？</h4><p><strong>分析：</strong> 回答分布式锁的方式，要点是说：到底是谁竞争锁，竞争之后多久释放</p>
<p><strong>回答：</strong> 我们是使用分布式锁的方式，worker 在拉取任务之前，会竞争一个分布式锁，拿到了分布式锁才能占据任务，为了提高速度，我们是占据任务成功之后，然后就释放锁，这样并发受到的影响稍微小一些。</p>
<h4 id="13、为什么不用-MySQL-自带的锁？"><a href="#13、为什么不用-MySQL-自带的锁？" class="headerlink" title="13、为什么不用 MySQL 自带的锁？"></a>13、为什么不用 MySQL 自带的锁？</h4><p><strong>分析：</strong> 不主动提随机竞争方案，但如果面试官问到了为什么不使用 MySQL 锁的时候，就可以从冲突时 CPU压力不稳定的角度回答</p>
<p><strong>回答：</strong></p>
<p>​	我也考虑过用 MySQL 自带的锁，并且有两个思路，第一个就是拉任务用 for update 语句，但这产生的间隙锁容易对其他 SQL 语句产生影响，并且《高性能MySQL》也是不推荐使用 for update 这种方式的。</p>
<p>​	第二个思路是先拉一次任务，然后将这批任务设置为执行中，并设置自己为 owner，接着再拉一次执行中并且标记是 woner 的任务，但这个方案也有缺点：一个是多次 SQL 调用；第二个是当 worker 多一点的时候，碰撞容易很激烈，都是抢头部 200 个任务，去竞争设置他们，大量的锁排队，这样测试下来也发现 MySQL CPU 不稳定，冲突激烈时会很高，而且因为冲突的随机性，业务执行性能不稳定，而且很难预知。</p>
<p>​	所以采用分布式锁的方式，避免这种冲突，也减少 SQL 调用次数。</p>
<h4 id="14、用了分布式锁，一个任务就一定不会被多个-worker-同时拿到吗？"><a href="#14、用了分布式锁，一个任务就一定不会被多个-worker-同时拿到吗？" class="headerlink" title="14、用了分布式锁，一个任务就一定不会被多个 worker 同时拿到吗？"></a>14、用了分布式锁，一个任务就一定不会被多个 worker 同时拿到吗？</h4><p><strong>分析：</strong> 在问你对分布式锁的理解，世界上没有完全可靠的分布式锁。</p>
<p><strong>回答：</strong> </p>
<p>​	不一定，分布式锁只能说在绝大多数的情况下，都能让一个任务被一个 worker 拿到。但是如果发生了一些异常，比如 worker 陷入 gc，锁又过期了，这时候就会被其他 worker 拿到，这时候头一个 worker 恢复过来了，他们就同时执行一个任务。</p>
<p>​	所以这里，业务自身是需要做幂等的。</p>
<h4 id="15、竞争分布式锁这种方式，会不会有什么问题？"><a href="#15、竞争分布式锁这种方式，会不会有什么问题？" class="headerlink" title="15、竞争分布式锁这种方式，会不会有什么问题？"></a>15、竞争分布式锁这种方式，会不会有什么问题？</h4><p><strong>分析：</strong></p>
<p>​	主要从抢锁操作会成为系统瓶颈，导致 worker 无法水平扩容的角度出发，分析具体逻辑，再进一步抽象这个问题。本质上是由于同步拉取和并发执行两个操作的耦合导致的，最后再踢出使用单独服务拉取任务到消息队列的解耦方案</p>
<p><strong>回答：</strong> </p>
<p>​	加入分布式锁之后，分布式锁的抢锁操作可能成为一个瓶颈，影响 worker 的水平扩容。因为每个 worker 在拉取任务之前都需要抢分布式锁，所有 worker 越多，抢分布式锁的竞争就越激烈，如果锁持有时间是一定的，则一个时间段可以抢到锁的 worker 数量是有限的，这也限制了 worker 的水平扩容。同时，worker 在抢锁失败之后需要等段时间再次抢锁，使得大量 worker 可能只是空转，浪费了资源。</p>
<p>​	总体上来说，导致这个问题的本质原因是在设计中将同步拉取和并发执行两个操作耦合，如果要进一步解决这个问题还是要思考将两个操作解耦。</p>
<p>​	这里我也考虑过优化方案，可以说一下么 (ps:如果让说，就是叙述单独服务拉取任务到消息队列的解耦方案）</p>
<h4 id="16、不使用-Redis，如何解决多机竞争问题？设计一个新方案"><a href="#16、不使用-Redis，如何解决多机竞争问题？设计一个新方案" class="headerlink" title="16、不使用 Redis，如何解决多机竞争问题？设计一个新方案"></a>16、不使用 Redis，如何解决多机竞争问题？设计一个新方案</h4><p><strong>分析：</strong> 提出这个问题，说明面试官看到 Redis 分布式锁这里的瓶颈，很敏锐。</p>
<p>​	这里可以直接回答怎么做，但是更好的是先自然而然阐述下，自己对分布式瓶颈的思考，这样才能凸显出分布式锁的优势。</p>
<p><strong>回答：</strong> 其实我也考虑过这个问题，分布式锁会带来 worker 无法水平扩容的问题，本质是同步拉取和并发执行的耦合，所以这里引入一个拉取服务，专门用来拉取并占据任务，然后扔入 kafka，通过 kafka 多分区特性，worker 就可以并发消费了，这样就实现了解耦。</p>
<h4 id="17、你采用的是多台-worker-竞争任务的方式，那这样会不会出现有些-worker-在执行大量任务，但是一部分-worker-处于空闲的状态呢？"><a href="#17、你采用的是多台-worker-竞争任务的方式，那这样会不会出现有些-worker-在执行大量任务，但是一部分-worker-处于空闲的状态呢？" class="headerlink" title="17、你采用的是多台 worker 竞争任务的方式，那这样会不会出现有些 worker 在执行大量任务，但是一部分 worker 处于空闲的状态呢？"></a>17、你采用的是多台 worker 竞争任务的方式，那这样会不会出现有些 worker 在执行大量任务，但是一部分 worker 处于空闲的状态呢？</h4><p><strong>分析：</strong> </p>
<p>​	我们以分布式锁的方案来讨论，我们的 worker 占据任务之后，在执行前就释放了锁，这个时间很短，这种情况下执行时间才是大头，那第一个 worker 还在执行中，其他 worker 就可以拉到任务，不会出现所谓一部分 worker 处于空闲，如果出现了，那其实就是 worker 太多了。</p>
<p><strong>回答：</strong></p>
<p>​	不会的，我们占据任务之后，就会释放锁，这个是在执行之前，假设资源配置合理，那多台机器都会有任务去做。如果出现有机器闲置，说明可以缩容。</p>
<p>​	另外，为了避免任务比较少时，一个 worker 老是竞争成功这种不均衡的情况，我们也加入一个随机的间隔时间，以增加更多随机性</p>
<h4 id="18、任务如果执行中-worker-挂掉怎么办"><a href="#18、任务如果执行中-worker-挂掉怎么办" class="headerlink" title="18、任务如果执行中 worker 挂掉怎么办?"></a>18、任务如果执行中 worker 挂掉怎么办?</h4><p><strong>分析:</strong>	</p>
<ul>
<li><p>如果 worker 挂了，那么之前拉取的任务就处于执行中的状态</p>
</li>
<li><p>不会再被调度那么这就有任务卡死的现象 </p>
</li>
<li><p>任务治理服务会定义检查是否有长期处于执行中卡死的任务</p>
</li>
<li><p>如果有，任务治理服务会获取这些卡死的服务，并将他们的状态重置为待执行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">seelect * from A where status = 2 and now() &gt; modify_time + max_processing_time<br></code></pre></td></tr></table></figure></li>
</ul>
<p><strong>回答</strong>：</p>
<p>​	任务会停留在执行中的状态，框架提供最大执行时间配置，超过执行时间就会由任务治理重置任务，由于我们保存了上下文，所以下次再做的时候会从最新阶段开始做，这样一部分已经做过的事情就不会重复做了。</p>
<h4 id="19、那你是怎么得出分布式锁性能很差，然后要引入MQ的结论的？是理论上绝对比较差，还是实际上观察到的比较差。你应该是先遇到问题，然后才想着去优化吧？而不是拍脑袋的一个决定。"><a href="#19、那你是怎么得出分布式锁性能很差，然后要引入MQ的结论的？是理论上绝对比较差，还是实际上观察到的比较差。你应该是先遇到问题，然后才想着去优化吧？而不是拍脑袋的一个决定。" class="headerlink" title="19、那你是怎么得出分布式锁性能很差，然后要引入MQ的结论的？是理论上绝对比较差，还是实际上观察到的比较差。你应该是先遇到问题，然后才想着去优化吧？而不是拍脑袋的一个决定。"></a>19、那你是怎么得出分布式锁性能很差，然后要引入MQ的结论的？是理论上绝对比较差，还是实际上观察到的比较差。你应该是先遇到问题，然后才想着去优化吧？而不是拍脑袋的一个决定。</h4><p><strong>分析：</strong></p>
<p>​	架构的设计需要有前瞻性，可以不做，但是不能没考虑到</p>
<p>​	最终不做的理由，也是面试官所说的，没有遇到瓶颈，为何要去优化</p>
<p><strong>回答：</strong></p>
<p>​	主要是通过理论设计到这个优化，属于是做完项目的一个 review。同时也考虑到分布式锁在大多数场景都是够用了，同时也没有实际场景因为分布式锁遇到性能瓶颈，所以还没有去这么做，原则就是不过度去实现</p>
<h4 id="20、你在这个项目里用-mysql-是比较多的，那有用到事务吗？"><a href="#20、你在这个项目里用-mysql-是比较多的，那有用到事务吗？" class="headerlink" title="20、你在这个项目里用 mysql 是比较多的，那有用到事务吗？"></a>20、你在这个项目里用 mysql 是比较多的，那有用到事务吗？</h4><p><strong>分析：</strong>	</p>
<p>​	这是询问业务细节，也是想通过询问细节知识点进一步了解项目</p>
<p><strong>回答：</strong></p>
<p>​	我们的业务没有主动开启事务，目前没有地方设计 2 张表的更新操作，也没有主动加 for update 锁的场景，都是单独的 sql 语句去处理的。</p>
<h1 id="分表"><a href="#分表" class="headerlink" title="分表"></a>分表</h1><h4 id="1、分表为什么自己写，为什么不用组件？"><a href="#1、分表为什么自己写，为什么不用组件？" class="headerlink" title="1、分表为什么自己写，为什么不用组件？"></a>1、分表为什么自己写，为什么不用组件？</h4><p><strong>分析：</strong></p>
<ol>
<li>我们需要按大小迭代</li>
<li>老表热度越来越低</li>
<li>业界组件不支持按大小分片</li>
<li>自己实现成本低</li>
</ol>
<p><strong>回答：</strong></p>
<p>​	常见的组件比如 MyCat 分表，是按照业务字段 hash，比如 useid hash 不同用户到不同的分片里。</p>
<p>​	而在我们的框架里面，是需要按照大小来迭代新表的（达到500万条数据就分表）</p>
<p>​	并且思路是老表逐渐作废，不是多个分片长期提供服务，相当于一个窗口不断的滑动</p>
<p>​	同时这个分表逻辑并不复杂，评估了成本和需求之后决定自己做</p>
<h4 id="2、分表难在哪里"><a href="#2、分表难在哪里" class="headerlink" title="2、分表难在哪里"></a>2、分表难在哪里</h4><p><strong>分析：</strong> 其实分表不难，但这里需要把一个不难的事情，讲得听起来有点难度，以及是校招，可以定位成对学生而言很难</p>
<p><strong>回答：</strong></p>
<p>​	难点我觉得有两个方面：</p>
<ol>
<li><p>选型上，我们其实是二维分表，一个是 taskType 来做了隔离</p>
<p>，另一个是根据大小进行了滚动分表，这里我们没有按调研的常用分表组件来做，而是选了适合我们的方式，我觉得这个是有一定难度的</p>
</li>
<li><p>实现上的细节设计考虑点还是很多，比如什么时候分表、谁来分表、怎么降低检查分表对性能的影响。比如我们一开始是想在创建认为时来 count(*) 来检查，但是考虑到这会造成性能问题，</p>
<p>[^性能问题]: count(*) 是全表扫描，创建一次插入请求可能是20 ms，但是加入一个 count(*) 操作可能就变成了800 ms，接口性能就急剧下降了</p>
<p>所以选择了定时检查，容忍了一定程度的延迟。比如还有一个问题，我们分表之后，怎么快速查询到某个任务在哪张表？这里我们选择了通过在任务 ID 上做手脚，加了个数字尾巴，这种方式减少了查询成本。这些细节其实都花了不少心思去设计。</p>
</li>
</ol>
<p>​	总的来说，我认为这里的难点在于整体选型及细节设计上。</p>
<blockquote>
<p>​	可能这个对于工作经验很丰富的人来说确实不算很难，但我真的是一步一步从 0 到 1 摸索出来的，对我而言还是很有挑战和难度的。</p>
</blockquote>
<h4 id="3、介绍你的分表方式？"><a href="#3、介绍你的分表方式？" class="headerlink" title="3、介绍你的分表方式？"></a>3、介绍你的分表方式？</h4><p><strong>分析：</strong></p>
<p>​	要点：</p>
<ol>
<li>按大小分表</li>
<li>分表之后消费产生的变化</li>
</ol>
<p><strong>回答：</strong></p>
<p>​	我们的任务达到一定阈值就会发生分表，分表之后新增任务写入新表，消费还是走老表，老表消费完成之后再消费到新表。消费几号表、写入几号表，这个信息我们也是通过一张单独的任务位置表记录的。</p>
<h4 id="4、为什么按大小分表？"><a href="#4、为什么按大小分表？" class="headerlink" title="4、为什么按大小分表？"></a>4、为什么按大小分表？</h4><p><strong>分析：</strong> </p>
<ol>
<li>我们的任务执行完了基本就冷了，和账单那种随时间变冷很像，其实我们会更冷一些</li>
<li>这里要明确，我们其实更偏向于滚表，但是我们之前的数据还能支持提供按 id 查询等能力，所以分表是 ok 的</li>
</ol>
<p><strong>回答：</strong></p>
<p>​	我们是记录任务，任务一般做完之后，很快就变成了比较冷的数据，甚至某些业务1、2月前的历史数据都可以删除掉，所以更适合这种滚动分表</p>
<p>​	分表之后，我们的任务消费、任务创建这种主要操作都是发生在热表上，通过任务 id 查询任务信息这类操作则可以通过后缀快速去对应的表查，无论冷热</p>
<p>​	这种策略对性能友好、也对后面存储友好，同时也非常适合我们的场景</p>
<h4 id="5、我觉得与其管理任务位置，为什么不通过时间分表呢？你这个实现方式应该挺复杂的，需要记录任务位置，我可以预估一个任务量，然后按照时间分就可以了。比如你一天-10W-条，10-天-100W，那你两个月分一次就可以了，不用这么麻烦"><a href="#5、我觉得与其管理任务位置，为什么不通过时间分表呢？你这个实现方式应该挺复杂的，需要记录任务位置，我可以预估一个任务量，然后按照时间分就可以了。比如你一天-10W-条，10-天-100W，那你两个月分一次就可以了，不用这么麻烦" class="headerlink" title="5、我觉得与其管理任务位置，为什么不通过时间分表呢？你这个实现方式应该挺复杂的，需要记录任务位置，我可以预估一个任务量，然后按照时间分就可以了。比如你一天 10W 条，10 天 100W，那你两个月分一次就可以了，不用这么麻烦"></a>5、我觉得与其管理任务位置，为什么不通过时间分表呢？你这个实现方式应该挺复杂的，需要记录任务位置，我可以预估一个任务量，然后按照时间分就可以了。比如你一天 10W 条，10 天 100W，那你两个月分一次就可以了，不用这么麻烦</h4><p><strong>分析：</strong></p>
<p>​	其实本质还是可以按时间划分的，老表时间肯定比新表早，但区别在于，触发的时机不是固定的时间分割，而是大小分割，为的是一个及时性和数据量均匀性</p>
<p><strong>回答：</strong></p>
<p>​	我觉得对于任务的增速和流量大小，很有可能是不平均，比如说秒杀场景，会有一大波任务过来，这种情况，我们如果靠一个平均的速率去预估进行分表，肯定是不合理的，很容易发送数据量超过分表阈值，但是没有及时分表影响性能的情况。我认为这里不如去定时扫描任务量，这样可以保证分表是及时的。</p>
<h4 id="6、你为了机器人项目做了一个框架？你量这么小，弄-500w-分表？"><a href="#6、你为了机器人项目做了一个框架？你量这么小，弄-500w-分表？" class="headerlink" title="6、你为了机器人项目做了一个框架？你量这么小，弄 500w 分表？"></a>6、你为了机器人项目做了一个框架？你量这么小，弄 500w 分表？</h4><p><strong>分析:</strong>	这个问题问得挺务实的，也是挑战你的出发点</p>
<p>​	被问到不要慌，首先我们这个是框架，框架又不是服务于单个场景，其次考虑成本收益，是站得住脚的</p>
<p><strong>回答：</strong></p>
<p>​	这个我们其实考虑的收益和成本。</p>
<p>​	首先，作为一个框架，我们需要能应对不同的情况，机器人项目虽然小，但其他异步场景一天几十万也是正常的，比如区块链场景，所以提供分表对我们而言让框架不那么玩具化，这是收益。</p>
<p>​	同时，从成本考虑，我们的分表方案其实偏向于滚表，到 500w 就产生新的表，旧表还有存活任务就继续消费旧表，新任务写入新表，实现起来代码量也比较少，思路也比较清晰，成本较低。</p>
<p>​	综合收益和成本来看，我觉得这个算前瞻性设计而不是过度设计。</p>
<h4 id="7、flower-怎么知道到达分表阈值了？轮询吗？这里有细节吗？当面试官说你不能就说判断到阈值了，这里总有代码实现，我想听细节"><a href="#7、flower-怎么知道到达分表阈值了？轮询吗？这里有细节吗？当面试官说你不能就说判断到阈值了，这里总有代码实现，我想听细节" class="headerlink" title="7、flower 怎么知道到达分表阈值了？轮询吗？这里有细节吗？当面试官说你不能就说判断到阈值了，这里总有代码实现，我想听细节"></a>7、flower 怎么知道到达分表阈值了？轮询吗？这里有细节吗？当面试官说你不能就说判断到阈值了，这里总有代码实现，我想听细节</h4><p><strong>分析：</strong> 几个要点</p>
<ol>
<li>要说我们有一个任务治理模块去做的，这个模块目前为了简单，是放在 flowsvr 的，其实应该独立出来</li>
<li>要听细节，就要将下实际是一个线程，具体使用了什么操作来进行的检查</li>
</ol>
<p>​	更进一步分析一下其他方案，以及为什么选择了 当前方案</p>
<p><strong>回答：</strong></p>
<p>​	我们有个任务治理模块去轮询，可以理解为有 个线程去 <code>count(*)</code> 查看总数是否达到阈值。</p>
<p>​	这里我们其实还考虑过在创建时判断，但是如果增加一个 <code>count(*)</code> 去判断，这样创建的吞吐会大幅降低，这种方式也可以进一步优化。</p>
<p>​	比如创建时同时在 Redis 中增加 1 ，这样可以用 Redis 来进行判断，至于 Redis 可能遗漏一些数据，本身对我们而言这个数据也不需要完全准确。</p>
<p>​	但为什么后面没这样做，是因为目前线程轮询的方式并不会带来瓶颈，虽然不是最好，但也够用，所以没去做太过前瞻的设计。</p>
<h4 id="8、如果读写请求大到单表处理不过来呢？"><a href="#8、如果读写请求大到单表处理不过来呢？" class="headerlink" title="8、如果读写请求大到单表处理不过来呢？"></a>8、如果读写请求大到单表处理不过来呢？</h4><p><strong>分析：</strong> 能问出这个问题，说明面试官很敏锐，抓住了我们这里无法水平扩展的问题。</p>
<p>​	我们的思路就两点：</p>
<ol>
<li>这块需要量很大才会成为瓶颈，而异步任务一般不会这么大，所以没过度设计</li>
<li>我们也思考过怎么扩展，虽然没做，但是考虑周全</li>
</ol>
<p><strong>回答：</strong></p>
<p>​	 我们的热点请求，都是任务调度相关的拉取和任务设置状态，这两个操作都有走索引。</p>
<p>​	通常来说普通的 MySQL 配置如 8 核 16 G，每秒 6000 是没什么问题的，这样 一小时可以支持2160 w任务，在异步场景下瓶颈通常也不在这里。</p>
<p>​	如果单表确实性能不够了，我们也可以支持按用户 Hash 分片，一个比较容易的方式是接入 tdsql 这种完全兼容 mysql 的数据库，可以自动分片。另外我们也打算提供 mongodb 这样天然支持分片的文档数据库用作任务管理，这个可以根据场景选择的。</p>
<h4 id="9、会不会出现-schedule-begin-pos-和-schedule-end-pos-跨不止-1-张表的情况？"><a href="#9、会不会出现-schedule-begin-pos-和-schedule-end-pos-跨不止-1-张表的情况？" class="headerlink" title="9、会不会出现 schedule_begin_pos 和 schedule_end_pos 跨不止 1 张表的情况？"></a>9、会不会出现 schedule_begin_pos 和 schedule_end_pos 跨不止 1 张表的情况？</h4><p><strong>分析：</strong>	考虑极端一点的情况</p>
<p><strong>回答：</strong></p>
<p>​	会，但可能性不高。比如突然一波海量流量，比如 worker 挂掉，长时间积累。</p>
<p>​	这种情况要么等待逐渐消耗，要么需要增加 worker 来提升吞吐。</p>
<h4 id="10、推荐分表的阈值是多少？为什么这么推荐？"><a href="#10、推荐分表的阈值是多少？为什么这么推荐？" class="headerlink" title="10、推荐分表的阈值是多少？为什么这么推荐？"></a>10、推荐分表的阈值是多少？为什么这么推荐？</h4><p><strong>分析：</strong>	</p>
<p>​	我们默认是 500w，这也是一个经验值，网上说的 2000w 3 层，我感觉可能也不是特别靠谱，可能重点还是是否请求基本全走索引，不是的话，2000 w 还是有压力的。</p>
<p><strong>回答：</strong></p>
<p>​	500w。网上推荐比较多的是把 B+ 树层数维持在三层，也就是最多 2000w。实践中这个数字其实应该更小一些，阿里巴巴就推荐 500w 数据分表，因为实际查询很多时候不全走索引场景，比如我们的场景需要支持比较丰富的任务管理，以及数量统计等请求。举个例子，查询某个用户当前进行中任务总数，以及分页查询，这些请求在 500w 左右就已经有压力了。</p>
<p>​	同时 500w 和 2000w 对于相对正常的任务消费而言，都是够用的，所以选择了 500w。</p>
<h4 id="11、分表时，如果任务全到-1-号表，0-号表是清掉吗？用什么语句清，为什么？这里有做设计吗？"><a href="#11、分表时，如果任务全到-1-号表，0-号表是清掉吗？用什么语句清，为什么？这里有做设计吗？" class="headerlink" title="11、分表时，如果任务全到 1 号表，0 号表是清掉吗？用什么语句清，为什么？这里有做设计吗？"></a>11、分表时，如果任务全到 1 号表，0 号表是清掉吗？用什么语句清，为什么？这里有做设计吗？</h4><p><strong>分析：</strong></p>
<p>​	这个问题还是确认分表细节，面试官这么问，我们其实并不知道他到底单纯想问已完成的表的清理，还是其实没理解我们的分表方案是滚动，所以我们再简述下我们的分表，再回答问题</p>
<p><strong>回答：</strong></p>
<p>​	分表之后，0 号表如果还有任务，是先消费 0 号表，完成之后再消费 1 号表，也就类似于一个老队列，需要先做完，再做新队列</p>
<p>​	这样滚动下去，历史的已完成的老表，就可以根据业务情况清理了，比如一个半年前的表，通常可以直接 drop 掉。</p>
<h4 id="12、能否继续往0-1-2-3-4-号表滚动，这样不久支持更多任务了？"><a href="#12、能否继续往0-1-2-3-4-号表滚动，这样不久支持更多任务了？" class="headerlink" title="12、能否继续往0 1 2 3 4 号表滚动，这样不久支持更多任务了？"></a>12、能否继续往0 1 2 3 4 号表滚动，这样不久支持更多任务了？</h4><p><strong>分析：</strong></p>
<p>​	提问不太清晰，直观理解应该是说 500w 太小了，一次滚多个表，存储就更大了。我们不要陷入他的提问来纠缠这种方式为啥不好，而是说我们有更好的方式</p>
<p><strong>回答：</strong></p>
<p>​	异步任务瓶颈在执行，而不是在任务拉取，通常来说单个表 500w 是够用了。但如果更进一步需要支持更多任务，我会选择用 TDSQL 这种分布式 MySQL，或者 MongoDB 这样可以分片的数据库，这样单表的数据就可以进一步往上走，也就是说维持现在的编号分表，但是某个分表，比如 1 号表，他本身又是支持了分片的。</p>
<h4 id="13、你是对任务信息表分表，为什么不直接按照任务-id-分表，比如大于-5002-一张表，大于-1000w-一张表？"><a href="#13、你是对任务信息表分表，为什么不直接按照任务-id-分表，比如大于-5002-一张表，大于-1000w-一张表？" class="headerlink" title="13、你是对任务信息表分表，为什么不直接按照任务 id 分表，比如大于 5002 一张表，大于 1000w 一张表？"></a>13、你是对任务信息表分表，为什么不直接按照任务 id 分表，比如大于 5002 一张表，大于 1000w 一张表？</h4><p><strong>分析：</strong> 是可以按照 id 分，但是就耦合这个数据，同时创建之后就不知道 id 是多少了，还是得线程去轮询查，没有明星受益</p>
<p><strong>回答：</strong></p>
<p>​	用 id 分其实是可以的。但是考虑到 count 是最准确的，依赖于 id 这种递增规则，其实是不同用的做法。同时，如果使用 id，在创建之后也拿不到 id 是多少，也可能单独去查一次，还得单独开线程定时去查，这样做的话没有明显的收益，反而因为前面原因增加了心智成本，所以最终还是用 count 总数的方式。</p>
<h1 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h1><h4 id="1、你这个框架的性能怎么样"><a href="#1、你这个框架的性能怎么样" class="headerlink" title="1、你这个框架的性能怎么样"></a>1、你这个框架的性能怎么样</h4><p><strong>分析：</strong>	</p>
<p>​	性能其实在不同机器上测出来都不一样，我们给一个不离谱的数值就可以了，比如说是测出来 2000，如果想他问优化，就可以说是 500 优化到了 2000</p>
<p><strong>回答：</strong></p>
<p>​	我们这里测了主要的接口，包括创建任务、查询任务、占据任务等。其中创建任务能达到 2000，机器是 2 核 4 G 云虚拟机，原来是 500 qps，优化之后达到 2000 qps。</p>
<h4 id="2、选的是什么数据来测试？"><a href="#2、选的是什么数据来测试？" class="headerlink" title="2、选的是什么数据来测试？"></a>2、选的是什么数据来测试？</h4><p><strong>分析：</strong></p>
<p>​	这个应该是对着建立问业务细节，选择什么数据，应该是说什么数据量下，什么接口或者什么场景进行的测试，那么回答也需要细节一点</p>
<p><strong>回答：</strong></p>
<p>​	我们在数据库装满 500w 数据情况下，测试了创建任务、占据任务、查询任务结果这几个核心接口，创建任务和占据任务调优之后可以从 500 到 2000 qps，查询任务结构因为有缓存所以很轻松能达到 4000 以上 qps，没有进一步测他极限，理论上 Redis 查询是可以10 多万的。</p>
<h4 id="3、一开始的性能瓶颈是什么？"><a href="#3、一开始的性能瓶颈是什么？" class="headerlink" title="3、一开始的性能瓶颈是什么？"></a>3、一开始的性能瓶颈是什么？</h4><p><strong>分析：</strong></p>
<p>​	一开始是连接池压不上去，如果检验不是很深，切忌不要答得太过完美，留下一些 “不成熟” 反而是好事。注意是 MySQL 连接池</p>
<p><strong>回答：</strong></p>
<p>​	一开始是因为原来连接池设置过小，大概是 10，压力上去之后，QPS 大量降低，通过 netstat 观测到 TIME_WAIT 很多，同时出现端口耗尽报错，定位到是连接池问题，调大（2000）之后不再有端口耗尽问题，同时性能高了近一倍，提升这么多主要原因也是因为端口耗尽导致压力也上不去。后面就是 GC 成为了新瓶颈，再后面还接入缓存，大大提升了查询性能。</p>
<h4 id="4、你是怎么测试的"><a href="#4、你是怎么测试的" class="headerlink" title="4、你是怎么测试的"></a>4、你是怎么测试的</h4><p><strong>分析：</strong>	</p>
<p>​	问怎么测试有两个目的，一个看你是不是真的测试了，另一个也确实好奇你的测试方式，增加真实性，建议说多种方式。</p>
<p><strong>回答：</strong></p>
<p>​	一开始是自己写 Golang 程序来进行压测，但是后面感觉不够专业，就采用了 Wrk 这个轻量级开源工具进行测试，配合 Lua 脚本可以很方便地发起压测，支持设置并发数（100、200）、持续时间、间隔时间等参数。</p>
<h4 id="5、如果突然有特别多数据怎么处理呢？不考虑对-worker-进行扩容，不考虑增加机器，比如多了-50-这样的需求，框架的瓶颈在什么地方？这个模块会出什么问题"><a href="#5、如果突然有特别多数据怎么处理呢？不考虑对-worker-进行扩容，不考虑增加机器，比如多了-50-这样的需求，框架的瓶颈在什么地方？这个模块会出什么问题" class="headerlink" title="5、如果突然有特别多数据怎么处理呢？不考虑对 worker 进行扩容，不考虑增加机器，比如多了 50% 这样的需求，框架的瓶颈在什么地方？这个模块会出什么问题"></a>5、如果突然有特别多数据怎么处理呢？不考虑对 worker 进行扩容，不考虑增加机器，比如多了 50% 这样的需求，框架的瓶颈在什么地方？这个模块会出什么问题</h4><p><strong>分析：</strong></p>
<p>​	这个问题其实挺难的，属于一道优化的开放题，没有标准答案，建议以开放的思路来进行回答，展现思考。</p>
<p>​	分多个方向提吧，数据库是最容易成为瓶颈的，先提数据库，然后从方案设计，然后从 worker 程序优化。</p>
<p><strong>回答：</strong></p>
<p>​	我觉得瓶颈可能考虑三个地方：</p>
<ol>
<li>从数据库来看，我们拉取之前会判断是否这个任务类型达到了当前能执行的最大个数，这种 count 的操作数，也容易成为瓶颈，这里可以做一个 Redis 缓存，定时刷新（1~10s)，这样也能提升执行时的吞吐</li>
<li>从设计来看，我们刚刚提到的消息队列解耦方式，也能提高吞吐</li>
<li>从 worker 程序本身来看， HTTP 连接池、GC 回收阈值参数，这些也可以进一步调优，这个时间的话需要结合测试。</li>
</ol>
<h4 id="6、任务积压怎么解决、怎么发现，不能说积压了就甩给-worker-不管了。"><a href="#6、任务积压怎么解决、怎么发现，不能说积压了就甩给-worker-不管了。" class="headerlink" title="6、任务积压怎么解决、怎么发现，不能说积压了就甩给 worker 不管了。"></a>6、任务积压怎么解决、怎么发现，不能说积压了就甩给 worker 不管了。</h4><p><strong>分析：</strong></p>
<ol>
<li>积压是队列化场景常见问题</li>
<li>解决思路可以从多个方向去说</li>
<li>这个功能属于细节加强，目前没有实现，通过这个问题正好可以思考出一些方案</li>
</ol>
<p><strong>回答：</strong></p>
<p>​	首先我们可以通过日志（记录当前还没有消费的任务个数）和监控发现积压，同时我们在拉取任务是会检查当前任务总数的，这时候也能发现。</p>
<p>​	如果积压不严重的话，我们可以扩容 worker 来解决</p>
<p>​	如果积压太过严重，老任务已经受影响了，可以考保新任务，我们这里基于分表逻辑来处理：简单来说，是发现积压国中时，通过触发一个特殊的分表接口，主动分表，老数据设置为失败，用户重试即可。</p>
<h4 id="7、你是如何调优的？"><a href="#7、你是如何调优的？" class="headerlink" title="7、你是如何调优的？"></a>7、你是如何调优的？</h4><p><strong>分析：</strong></p>
<p>​	有几个点可以说，连接池、工具包、GC、缓存，性能调优是个难题，如果经验不是很深，切忌不要答得太过完美</p>
<p><strong>回答：</strong></p>
<p>​	我是一步一步，从三个方面调优的：</p>
<ol>
<li>连接池调优：原来连接池设置过小，大概是 10，压力上去之后，QPS 大量降低，通过 netstat 观测到 TIME_WAIT 很多，同时出现端口耗尽报错，定位到是连接池的问题，调大之后不再有端口耗尽问题，同时性能提高了近一倍，提升这么多主要原因也是端口耗尽导致压力也上不去。</li>
<li>GC 调优：默认的配置下，新申请的内存只要达到上次预留的 1:1 大小，就会触发 GC，在高压下是很容易触发的，于是我们将配置比调大了 10 倍，达到 10:1 才会触发，这种策略大大减少了 GC 的次数，性能提升了 20% 左右</li>
<li>日志库优化：Golang 原来用的是 seelog，这里主要是考虑 seelog 是最古老最成熟的日志库，但实际使用下来性能是真的低，这里优化成 zaplog 之后，性能提高了 50%</li>
</ol>
<h4 id="8、那如果有更多-TIME-WAIT-状态连接-你会怎么处理？继续调大参数？"><a href="#8、那如果有更多-TIME-WAIT-状态连接-你会怎么处理？继续调大参数？" class="headerlink" title="8、那如果有更多 TIME_WAIT 状态连接 你会怎么处理？继续调大参数？"></a>8、那如果有更多 TIME_WAIT 状态连接 你会怎么处理？继续调大参数？</h4><p><strong>分析：</strong></p>
<p>​	这个预设条件有问题，调大之后如果压力进一步放大，先达到瓶颈的是 MySQL</p>
<p><strong>回答：</strong></p>
<p>​	单个 worker 对于 MySQL 的连接数 2000 已经够多了，不会再继续堆积 TIME_WAIT，此时我们的瓶颈是 MySQL。</p>
<h4 id="9、你不是说你的-worker-只有六台吗？六台-worker-拉取任务需要-2000-qps？"><a href="#9、你不是说你的-worker-只有六台吗？六台-worker-拉取任务需要-2000-qps？" class="headerlink" title="9、你不是说你的 worker 只有六台吗？六台 worker 拉取任务需要 2000 qps？"></a>9、你不是说你的 worker 只有六台吗？六台 worker 拉取任务需要 2000 qps？</h4><p><strong>分析：</strong></p>
<p>​	这个问题是说 6 台 worker，就算都是 1s 一次拉取，也只需要 6qps，为啥要测到 2000.</p>
<p>​	回答的思路从我们的定位是框架来说，也可以说一下测到 2000 并没有带来太多的额外成本。</p>
<p><strong>回答：</strong></p>
<p>​	我们是框架，我们的场景虽然不需要这么高的 qps，但是我们会测到一个相对高的数值。不只是这个接口，创建任务、拉取任务、查询任务等我们都做了。虽然拉取任务不需要 2000，但我们压测适度调优就达到了 2000，属于一个非常够用的值。</p>
<h4 id="10、那你是怎么得出这里的性能很差，然后要引入MQ的结论的呢-是理论上觉得比较差，还是实际上观察到的比较差。你应该是先遇到问题，然后才想着去优化吧，而不是拍脑袋的一个决定的吧？"><a href="#10、那你是怎么得出这里的性能很差，然后要引入MQ的结论的呢-是理论上觉得比较差，还是实际上观察到的比较差。你应该是先遇到问题，然后才想着去优化吧，而不是拍脑袋的一个决定的吧？" class="headerlink" title="10、那你是怎么得出这里的性能很差，然后要引入MQ的结论的呢? 是理论上觉得比较差，还是实际上观察到的比较差。你应该是先遇到问题，然后才想着去优化吧，而不是拍脑袋的一个决定的吧？"></a>10、那你是怎么得出这里的性能很差，然后要引入MQ的结论的呢? 是理论上觉得比较差，还是实际上观察到的比较差。你应该是先遇到问题，然后才想着去优化吧，而不是拍脑袋的一个决定的吧？</h4><p><strong>分析：</strong></p>
<p>​	这个问题的核心是挑战你为啥没有瓶颈去优化，回答主要也要解答这人问题，思路就是你说的对，没瓶颈就不要优化，我们只是设想了，没真的去做。<br><strong>回答：</strong><br>​	我们主要是通过理论设想到这个优化，在做完项目之后，我们组织了一个复盘会议，进行一些功能和设计的<br>Review，就设想到了这人优化。<br>​	但是因为确实没有实际问题，同时也考虑到这需要很大量级才会出现，起码得几十个worker才会真正带来问题<br>所以还没有这么去做。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E9%9D%A2%E8%AF%95/" class="category-chain-item">面试</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E9%9D%A2%E8%AF%95/">#面试</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Asyncflow</div>
      <div>http://example.com/2023/08/04/面试/Asyncflow/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Feng Tao</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年8月4日</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>更新于</div>
          <div>2023年8月5日</div>
        </div>
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/08/05/Go%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/for-range2/" title="for-range">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">for-range</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/08/04/Go%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/%E7%9F%AD%E5%8F%98%E9%87%8F%E5%A3%B0%E6%98%8E%E7%9A%84%E5%B0%8F%E7%BB%86%E8%8A%82/" title="短变量声明的小细节">
                        <span class="hidden-mobile">短变量声明的小细节</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"n0H6ZjcwsAdPc2zfOJM4bxV4-gzGzoHsz","appKey":"rwjeQIHfYJqQvjh2iWuPkYev","path":"window.location.pathname","placeholder":"匿名评论，畅所欲言","avatar":"robohash","meta":["nick","mail"],"requiredFields":[],"pageSize":20,"lang":"zh-CN","highlight":true,"recordIP":true,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":true},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  








    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> <div style="font-size: 0.85rem"> <span id="timeDate">载入天数...</span> <span id="times">载入时分秒...</span> <script src="/js/duration.js"></script> </div> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问量 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        总访客数 
        <span id="leancloud-site-uv"></span>
         人
      </span>
    
    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>

<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/love.js"></script>

<!--动态线条背景-->
<script type="text/javascript"
color="220,220,220" opacity='0.7' zIndex="-2" count="200" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js">
</script>

<!-- 雪花特效 -->
<script type="text/javascript" src="\js\snow.js"></script>